{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face mosaic_video.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMEwgxgppLxbVyw5ydFvBOR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_n_AKFzJzFBV","executionInfo":{"status":"ok","timestamp":1635680735394,"user_tz":-540,"elapsed":18074,"user":{"displayName":"송정현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03834848729540117659"}},"outputId":"26d44574-24c4-4efa-ef29-bfba16eba66a"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"P82UwSbzzYUY","executionInfo":{"status":"ok","timestamp":1635680932659,"user_tz":-540,"elapsed":1158,"user":{"displayName":"송정현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03834848729540117659"}}},"source":["import cv2\n","face_cascade_name = '/content/gdrive/MyDrive/Face_Mosaic/haarcascade_frontalface_alt.xml'     # 얼굴을 인식하는 feature 파일\n","file_name = '/content/gdrive/MyDrive/Face_Mosaic/mama.mp4' # 원본 동영상          \n","output_name = 'output_mama.mp4'  # detection 된 output 동영상\n","ratio = 0.05  # 얼굴영역 축소 비율 초기값"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3SjOw9Hzh6B","executionInfo":{"status":"ok","timestamp":1635680935317,"user_tz":-540,"elapsed":3,"user":{"displayName":"송정현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03834848729540117659"}}},"source":["def detectAndDisplay(frame):\n","    # GRAY 이미지로 변환\n","    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    frame_gray = cv2.equalizeHist(frame_gray)\n","    #-- Detect faces\n","    faces = face_cascade.detectMultiScale(frame_gray)\n","    for (x,y,w,h) in faces:\n","      faceROI = cv2.resize(frame[y: y + h, x: x + w], None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)\n","      frame[y: y + h, x: x + w] = cv2.resize(faceROI, (w, h), interpolation=cv2.INTER_NEAREST)\n","    \n","    # video 를 disk 에 output 하기 위해 writer 를 초기화한다.\n","    global writer\n","    if writer is None and output_name is not None:\n","        fourcc = cv2.VideoWriter_fourcc(*\"DIVX\")    # 코덱 정의\n","        writer = cv2.VideoWriter(output_name, fourcc, 20,\n","                (frame.shape[1], frame.shape[0]), True)\n","        \n","    # disk 에 frame 을 write 합니다.\n","    if writer is not None:\n","        writer.write(frame)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"NztyRanD0QVG","executionInfo":{"status":"ok","timestamp":1635680939326,"user_tz":-540,"elapsed":924,"user":{"displayName":"송정현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03834848729540117659"}}},"source":["# face_cascade 인스턴스를 생성한다.\n","face_cascade = cv2.CascadeClassifier()\n","\n","# cascades 파일을 불러온다.\n","if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):\n","    print('--(!)Error loading face cascade')\n","    exit(0)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBMc7JR_0wS6","executionInfo":{"status":"ok","timestamp":1635680976893,"user_tz":-540,"elapsed":36027,"user":{"displayName":"송정현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03834848729540117659"}},"outputId":"7e1cc324-31f4-4439-aab8-b929d0d6ce97"},"source":["# 원본 동영상에서 video stream을 읽어온다.\n","cap = cv2.VideoCapture(file_name)\n","writer = None\n","if not cap.isOpened:\n","    print('--(!)Error opening video capture')\n","    exit(0)\n","while True:\n","    ret, frame = cap.read()\n","    if frame is None:\n","        # close the video file pointers\n","        cap.release()\n","        # close the writer point\n","        writer.release()\n","        print('--(!) No captured frame -- Break!')\n","        break\n","    detectAndDisplay(frame)  # frame 을 보낸다."],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--(!) No captured frame -- Break!\n"]}]}]}